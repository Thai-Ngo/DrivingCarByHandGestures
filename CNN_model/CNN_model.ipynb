{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # We'll be storing our data as numpy arrays\n",
    "import os # For handling directories\n",
    "from PIL import Image # For handling the images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg # Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7e8402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'05_thumb': 0,\n",
       " '06_index': 1,\n",
       " '04_fist_moved': 2,\n",
       " '02_l': 3,\n",
       " '03_fist': 4,\n",
       " '01_palm': 5,\n",
       " '10_down': 6,\n",
       " '09_c': 7,\n",
       " '08_palm_moved': 8,\n",
       " '07_ok': 9}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "for j in os.listdir('./leapGestRecog/00/'):\n",
    "    if not j.startswith('.'): # If running this code locally, this is to \n",
    "                              # ensure you aren't reading in hidden folders\n",
    "        lookup[j] = count\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1\n",
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "datacount = 0 # We'll use this to tally how many images are in our dataset\n",
    "for i in range(0, 10): # Loop over the ten top-level folders\n",
    "    for j in os.listdir('./leapGestRecog/0' + str(i) + '/'):\n",
    "        if not j.startswith('.'): # Again avoid hidden folders\n",
    "            count = 0 # To tally images of a given gesture\n",
    "            for k in os.listdir('./leapGestRecog/0' + \n",
    "                                str(i) + '/' + j + '/'):\n",
    "                                # Loop over the images\n",
    "                img = Image.open('./leapGestRecog/0' + \n",
    "                                 str(i) + '/' + j + '/' + k).convert('L')\n",
    "                                # Read in and convert to greyscale\n",
    "                img = img.resize((320, 120))\n",
    "                arr = np.array(img)\n",
    "                x_data.append(arr) \n",
    "                count = count + 1\n",
    "            y_values = np.full((count, 1), lookup[j]) \n",
    "            y_data.append(y_values)\n",
    "            datacount = datacount + count\n",
    "x_data = np.array(x_data, dtype = 'float32')\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(datacount, 1) # Reshape to be the correct size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "for i in range(0, 10):\n",
    "    plt.imshow(x_data[i*200 , :, :])\n",
    "    plt.title(reverselookup[y_data[i*200 ,0]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8eb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.reshape((datacount, 120, 320, 1))\n",
    "x_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5594bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7522e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(120, 320,1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fe4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
    "print(\"Accuracy:\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01cbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
